# **集群搭建**

## **索引**
[1. kafka、zookeeper](#1-kafkazookeeper)
&emsp;[1.1 配置](#11-配置)
&emsp;&emsp;[1.1.1 线上kafka配置](#111-线上kafka配置)
&emsp;&emsp;[1.1.2  虚拟机中的kafka配置](#112-虚拟机中的kafka配置)
&emsp;&emsp;[1.1.3 虚拟机中zookeeper配置](#113-虚拟机中zookeeper配置)
&emsp;&emsp;[1.1.4 安装、启动](#114- 安装启动)
&emsp;&emsp;[1.1.5 kafka相关命令](#115-kafka相关命令)
[2. kafka-manager](#2-kafka-manager)
&emsp;[2.1 下载源码编译](#21-下载源码编译)
&emsp;[2.2 配置sbt的maven仓库](#22-配置sbt的maven仓库)
&emsp;[2.3 解压编译后的包](#23-解压编译后的包)
&emsp;[2.4 启动](#24-启动)
[3. jenkins](#3-jenkins)
&emsp;[3.1 下载war包](#31-下载war包)
&emsp;[3.2 用java启动](#32-用java启动)
&emsp;[3.3 使用ssh](#33-使用ssh)
&emsp;&emsp;[3.3.1 安装插件](#331-安装插件)
&emsp;&emsp;[3.3.2 配置](#332-配置)
&emsp;&emsp;[3.3.3 定时删除任务执行日志](#333-定时删除任务执行日志)



## 1.kafka、zookeeper
### 1.1 配置
#### 1.1.1 线上kafka配置
```
broker.id=1
#port=9092
#advertised.host.name=183.131.54.163

listener.security.protocol.map=PLAINTEXT:PLAINTEXT,PLAINTEXT1:PLAINTEXT,PLAINTEXT2:PLAINTEXT,PLAINTEXT3:PLAINTEXT
listeners=PLAINTEXT://183.131.54.163:9092,PLAINTEXT1://120.199.83.35:9093,PLAINTEXT2://101.71.76.35:9094,PLAINTEXT3://172.18.54.163:9095
advertised.listeners=PLAINTEXT://183.131.54.163:9092,PLAINTEXT1://120.199.83.35:9093,PLAINTEXT2://101.71.76.35:9094,PLAINTEXT3://172.18.54.163:9095

num.network.threads=25
num.io.threads=24
socket.request.max.bytes=104857600
socket.receive.buffer.bytes=1048576
socket.send.buffer.bytes=1048576
log.dirs=/bbd/sata01/kafka01,/bbd/sata02/kafka01,/bbd/sata03/kafka01,/bbd/sata04/kafka01,/bbd/sata05/kafka01,/bbd/sata06/kafka01,/bbd/sata07/kafka01,/bbd/sata08/kafka01,/bbd/sata09/kafka01,/bbd/sata10/kafka01,/bbd/sata11/kafka01,/bbd/sata12/kafka01
#log.dirs=/bbd/ssd01/kafka/kafkadir
num.partitions=66
default.replication.factor=2
num.recovery.threads.per.data.dir=1
log.retention.hours=72
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=172.18.54.162:2181,172.18.54.163:2181,172.18.54.164:2181
zookeeper.connection.timeout.ms=6000
delete.topic.enable=true
#log.flush.interval.messages=10000
#log.flush.interval.ms=1000
queued.max.requests=2000
offsets.storage=zookeeper
#heartbeat.interval.ms=30000
#session.timeout.ms=100000

#max.partition.fetch.bytes=20971520
#max.poll.records=400
#max.poll.interval.ms=200000

#offsets.topic.num.partitions=66
#offsets.topic.replication.factor=3
```
#### 1.1.2  虚拟机中的kafka配置
```
broker.id=0

listener.security.protocol.map=PLAINTEXT:PLAINTEXT
listeners=PLAINTEXT://master:9092
advertised.listeners=PLAINTEXT://master:9092

num.network.threads=2
num.io.threads=2
socket.request.max.bytes=104857600
socket.receive.buffer.bytes=1048576
socket.send.buffer.bytes=1048576
log.dirs=/zz/data/kafka
num.partitions=6
default.replication.factor=1
num.recovery.threads.per.data.dir=1
log.retention.hours=72
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=master:2181,work1:2181,work2:2181
zookeeper.connection.timeout.ms=6000
delete.topic.enable=true
#log.flush.interval.messages=10000
#log.flush.interval.ms=1000
queued.max.requests=2000
offsets.storage=zookeeper
#heartbeat.interval.ms=30000
#session.timeout.ms=100000

#max.partition.fetch.bytes=20971520
#max.poll.records=400
#max.poll.interval.ms=200000

#offsets.topic.num.partitions=66
#offsets.topic.replication.factor=3
```

#### 1.1.3 虚拟机中zookeeper配置
```
tickTime=2000
initLimit=10
syncLimit=5
clientPort=2181
server.0=master:2888:3888
server.1=work1:2888:3888
server.2=work2:2888:3888
dataLogDir=/zz/data/zookeeper/logs
dataDir=/zz/data/zookeeper/data
autopurge.purgeInterval=6
autopurge.snapRetainCount=72
maxClientCnxns=1000
```

### 1.1.4 安装、启动
```
tar -zxvf zookeeper.tar.gz
tar -zxvf kafka.tar.gz
rm -f kafka.tar.gz zookeeper.tar.gz
ln -s kafka_2.11-0.10.2.0/ kafka
ln -s zookeeper-3.4.9/ zookeeper

mkdir -p /zz/data/kafka
mkdir -p /zz/data/zookeeper/logs /zz/data/zookeeper/data
echo "0" > /zz/data/zookeeper/data/myid

#添加kafka监控端口
bin/kafka-server-start.sh
export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G -Xmn1G -XX:PermSize=64m -XX:MaxPermSize=128m  -XX:SurvivorRatio=6  -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly"
export JMX_PORT="9999"

/zz/app/zookeeper/bin/zkServer.sh start
nohup /zz/app/kafka/bin/kafka-server-start.sh /zz/app/kafka/config/server.properties &
jps|grep Kafka
jps | grep Kafka | awk '{print $1}' | xargs kill -9
```

### 1.1.5 kafka相关命令
```
#创建主题
/zz/app/kafka/bin/kafka-topics.sh --create --topic test --replication-factor 1 --partitions 6 --zookeeper master:2181,work1:2181,work2:2181
#查看主题列表
/zz/app/kafka/bin/kafka-topics.sh --list --zookeeper master:2181,work1:2181,work2:2181
#kafka查看消费情况
/zz/app/kafka/bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group test_g --zookeeper master:2181,work1:2181,work2:2181
#生产
/zz/app/kafka/bin/kafka-console-producer.sh --broker-list master:9092,work1:9092,work2:9092 --topic test
#消费
/zz/app/kafka/bin/kafka-console-consumer.sh --zookeeper master:2181,work1:2181,work2:2181 --from-beginning
/zz/app/kafka/bin/bin/kafka-console-consumer.sh --bootstrap-server master:9092,work1:9092,work2:9092 --topic test --from-beginning
#从指定分区消费
/kafka-console-consumer.sh --bootstrap-server master:9092,work1:9092,work2:9092 --offset 101 --topic test --partition 0 --max-messages 10
```
## 2. kafka-manager
### 2.1 下载源码编译
> 参考地址：[http://blog.csdn.net/isea533/article/details/73727485](http://blog.csdn.net/isea533/article/details/73727485)
> kafka-manager github地址：[https://github.com/yahoo/kafka-manager](https://github.com/yahoo/kafka-manager)

### 2.2 配置sbt的maven仓库
- `vim ~/.sbt/repositories`
- ```
  [repositories]
  local
  aliyun: http://maven.aliyun.com/nexus/content/groups/public
  typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly
  ```
- `./sbt clean dist # 进入kafka-manager源码`
> 配置参考：http://www.scala-sbt.org/0.13.2/docs/Detailed-Topics/Library-Management.html#override-all-resolvers-for-all-builds

### 2.3 解压编译后的包
```
cp /zz/app/kafka-manager-1.3.3.16_src/target/universal/kafka-manager-1.3.3.16.zip /zz/app
unzip kafka-manager-1.3.3.16.zip

ln -s  /zz/app/kafka-manager-1.3.3.16 /zz/app/kafka-manager
cd kafka-manager
vim bin/kafka-manager  #加入JAVA_HOME，如果环境变量中有，不用设置了
vim conf/application.conf #修改kafka-manager.zkhosts，zookeeper的连接
```

### 2.4 启动
```
vim start.sh
rm -rf RUNNING_PID
kafka_manager_path=/zz/app/kafka-manager
nohup $kafka_manager_path/bin/kafka-manager -Dconfig.file=$kafka_manager_path/conf/application.conf -Dhttp.port=9001 &
```

## 3. jenkins
### 3.1 下载war包
- 下载地址：[https://jenkins.io/doc/book/installing/](https://jenkins.io/doc/book/installing/)

### 3.2 用java启动
```
nohup java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=9080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20 &
```

### 3.3 使用ssh
#### 3.3.1 安装插件
系统管理 -> 管理插件 -> 可选插件 -> (安装：Publish Over SSH, 安装：SSH plugin)
#### 3.3.2 配置
- `cp ~/.ssh/id_rsa /zz/app/jenkins/`
- 系统管理 -> 系统管理 -> Publish over SSH #添加Path to key(/zz/app/jenkins/id_rsa) 和 Key(id_rsa的内容)
- Credentials -> System -> Global credentials (unrestricted) -> Add Credentials #添加执行ssh的用户信息
  参考：[jenkins ssh remote hosts如何设置?](https://www.zhihu.com/question/63573975)
- 系统管理 -> 系统管理 -> SSH remote hosts #开始添加服务器，Credentials选择刚添加的Credentials

### 3.3.3 定时删除任务执行日志
```
find /zz/app/jenkins/jobs/*/builds/* -mtime +7 -type d | xargs rm -rf
```
有的文件可能太多，可以循环删除
```
OLD_IFS="$IFS"
IFS=$'\n' 
for i in `ls /zz/app/jenkins/jobs/`;do find /zz/app/jenkins/jobs/$i/builds/* -mtime +7 -type d | xargs rm -rf; done
IFS=$OLD_IFS
```


## 4](#)