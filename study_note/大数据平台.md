# 1. 日志采集
## 1.1 快手http质量数据日志采集
### 1.1.1 接收post过来的数据
- 服务器：c3n-zj-nb1-183-131-54-166
- 配置文件：/etc/td-agent/td-agent-kshttpkafka1.conf
- 使用的插件：
  - /opt/td-agent/embedded/lib/ruby/gems/2.1.0/gems/fluent-plugin-kafka-0.3.4/lib/fluent/plugin/out_kafka_buffered.rb
  - /opt/td-agent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.12.26/lib/fluent/plugin/in_http.rb
- 修改的插件：/opt/td-agent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.12.26/lib/fluent/plugin/in_http.rb
- 快手ip：
  123.59.169.35
  114.118.4.94
- 数据源：http://post-kslog.bbdcdn.net:80/kshttplog
- 目的地：kakfa，主题kshttplog
- 功能说明：做服务端，接收快手post过来的数据，解压body（body压缩了），入库kafka

### 1.1.2 处理 接收post过来的数据 入库es
- 服务器：c3n-zj-nb1-183-131-54-166
- 配置文件：
  /etc/td-agent/td-agent-kshttpes1.conf
  /etc/td-agent/kafkaconf/kshttpnew_kshttpgroup_fluentd132-es-1.conf
- 修改的插件：/opt/td-agent/embedded/lib/ruby/gems/2.1.0/gems/fluent-plugin-elasticsearch-1.6.0/lib/fluent/plugin/out_elasticsearch.rb
- 数据来源：kafka，主题：kshttplog
- 目的地：es，主题：kshttplogpron-*
- 功能说明：处理kafka中的快手质量数据入库到es

## 1.2 快手质量数据post到厂商
### 1.2.1 post到云帆
- 服务器：c3n-zj-nb1-183-131-54-163
- 配置文件：/bbd/ssd01/app/zz/flume/conf/kafkasource_httpsink.conf
- 数据源：kafka，主题：kshttplog
- 目的地：http://cdn.api.yfcdn.net/kuaishou/slow_speed/_send
- 功能说明：用flume将kafka中快手post过来的数据，post到云帆

### 1.2.2 post到腾讯
- 服务器：c3n-zj-nb1-183-131-54-165
- 配置文件：
  /etc/td-agent/kafkaconf/kshttpnew_kshttpgroup-tx_fluentd165-tx-1.conf
  /etc/td-agent/kafkaconf/kshttpnew_kshttpgroup-tx_fluentd165-tx-2.conf
- 数据源：kafka，主题：kshttplog
- 目的地：http://cdninfo.qcloud.com/gifshow-detail-juxun.php
- 功能说明：用fluentd将kafka中快手post过来的数据，post到腾讯

## 1.3 快手file质量数据采集
### 1.3.1 快手file日志下载
- 服务器：c3n-zj-nb1-183-136-128-49
- 脚本：/bbd/ssd01/zz/shell/task/03_kuaishou_filelog/start_downlog.sh
- 数据来源：从快手下载
- 快手下载服务地址：http://180.186.38.176/data/gxfwtTTKaXMBR/
- 目的地：服务器c3n-zj-nb1-183-136-128-49上12块磁盘上
- 功能说明：下载快手提供的质量数据日志文件

### 1.3.2 处理下载的日志到es
- 服务器：c3n-zj-nb1-183-136-128-49
- 配置文件：/bbd/ssd01/app/apache-flume-1.6.0-cdh5.8.3-bin/conf/ksfilelogs.conf
- 代码：
  flume_plugin\src\main\java\com\sinobbd\intercepter\KSIntercepter.java
  flume-ng-cdh5-1.6.0_5.8.3\flume-ng-sinks\flume-ng-elasticsearch-sink\src\main\java\org\apache\flume\sink\elasticsearch\ElasticSearchSinkKS.java
- 数据来源：服务器c3n-zj-nb1-183-136-128-49上12块磁盘上的快手质量数据日志文件
- 目的地：es，索引：ksfilelog-*
- 功能说明：flume采集kafka中的快手质量数据入库es

## 1.4 自建日志采集
### 1.4.1 自建日志增强
- 服务器：183.131.54.[162 - 166]
- 配置文件：/bbd/ssd01/app/apache-flume-1.6.0-cdh5.8.3-bin/conf/jx_src_kafka.conf
- 代码：flume_plugin\src\main\java\com\sinobbd\bigdata\rockman\flume\JsonSrcIntercepter.java
- 数据来源：kafka，主题："nginx-access"
- 目的地：kafka，主题："strong-nginx-access"
- 功能说明：读取kafka中的自建的原始日志，增强后重新入库到kafka中

### 1.4.2 自建增强日志入hbase
- 服务器：183.136.128.[51 - 54]
- 配置文件：/bbd/ssd01/app/apache-flume-1.6.0-cdh5.8.3-bin/conf/JXflumeHbase.conf
- 代码：flumeHbase\src\main\java\com\sinobbd\FlumeToHbaseJX1.java
- 数据来源：kafka，主题："strong-nginx-access"
- 目的地：hbase，表："jx*"
- 功能说明：读取kafka中增强后日志入库到hbase中

### 1.4.2 自建增强日志入es
- 服务器：c3n-zj-nb1-183-131-54-147
- 启动脚本：/bbd/ssd01/zz/shell/jxLogToEs/start_nohup.sh
- 代码：hadoopStats\src\main\scala\com\sinobbd\jx\JXLogToEs.scala
- 数据来源：kafka，主题："strong-nginx-access"
- 目的地：es，索引：“nginx-*”，eg：nginx-2018.02.24
- 功能说明：读取kafka中增强后日志入库到es中

## 1.5 融合日志采集
### 1.5.1 融合日志入kafka
- 服务器：183.131.54.[162 - 166]、183.136.128.[49 - 54]
- 配置文件：/bbd/ssd01/app/apache-flume-1.6.0-cdh5.8.3-bin/conf/flume_kafka.conf
- 代码：flume_plugin\src\main\java\com\sinobbd\source\NewSpoolDirectorySource.java
- 数据来源：服务器183.131.54.[162 - 166]、183.136.128.[49 - 54]上的12快盘的厂商日志文件
- 目的地：kakfa，主题：“firm_logs”
- 功能说明：采集下载的厂商的日志文件增强入库kafka

## 1.6 php业务日志采集
- 服务器：c3n-zj-nb1-183-136-128-50
- 配置文件：/bbd/ssd01/app/apache-flume-1.6.0-cdh5.8.3-bin/conf/phpdev_sink_es.conf
- 代码：flume-ng-cdh5-1.6.0_5.8.3\flume-ng-sinks\flume-ng-elasticsearch-sink\src\main\java\org\apache\flume\sink\elasticsearch\ElasticSearchSinkPHPDEV.java
- 数据来源：kafka，主题：dev_php_noah
- 目的地：es，索引：dev_php_noah
- 功能说明：采集kafka中的php业务日志，入库到es

# 2. 日志打包
## 2.1 正常包
- 服务器：c3n-zj-nb1-183-131-54-147
- 脚本：
  /bbd/ssd01/zz/shell/task/logpackage_v2/start_logpackage_1.sh
  /bbd/ssd01/zz/shell/task/logpackage_v2/start_logpackage_2.sh
- 代码：flumeHbase\src\main\java\com\sinobbd\mapreduce\RHAndJXLogPackage3.java
- 数据源：hbase，昨天的自建、融合的表
- 目的地：服务器c3n-zj-nb1-183-131-54-136上，目录：/nfs/data/customer_logs
- 功能说明：打包昨天自建、融合日志包供客户下载

## 2.2 延迟包
- 服务器：c3n-zj-nb1-183-131-54-147
- 脚本：/bbd/ssd01/zz/shell/task/logpackage/start_logpackage_timeout.sh
- 代码：flumeHbase\src\main\java\com\sinobbd\mapreduce\TimeoutLogpackage.java
- 数据源：hbase，表：前天和大前天自建、融合表
- 目的地：服务器c3n-zj-nb1-183-131-54-136上，目录：/nfs/data/customer_logs
- 功能说明：打包自建、融合延迟日志包供客户下载


## 2.3 删除入库url
- 服务器：c3n-zj-nb1-183-131-54-147
- 脚本：/bbd/ssd01/zz/shell/delete_logpackageurl/delete_url.sh
- 功能说明：删除无用的入库的日志打包下载url，例如修复打包日志，删除日志同时删除入库的下载url

# 3. 监控
## 3.1 es各节点进程监控(jenkins)
- 服务器：183.136.128.47
  ```
  * * * * *
  /bbd/ssd01/zz/shell/task/01_watch/esnode_process_watch/esnode_process_watch.sh
  ```
## 3.2 flume、kafka监控(jenkins)
- 服务器：183.136.128.47
  ```
  */5 * * * *
  /bbd/ssd01/zz/shell/task/01_watch/server_watch_main.sh flume
  /bbd/ssd01/zz/shell/task/01_watch/server_watch_main.sh kafka
  ```
## 3.3 jenkins报活(jenkins)
- 服务器：183.136.128.47
  ```
  */5 * * * *
  echo "时间:`date '+%Y-%m-%d %H:%M:%S'` , timeUnix:`date +%s`" > /bbd/ssd01/zz/shell/task/01_watch/jenkins_machine_watch/logs/record_time

  #c3n-zj-nb1-183-131-54-135服务器上的crontab
  * * * * * sh /bbd/ssd01/zz/shell/task/01_watch/jenkins_machine_watch/128-47_watch.sh  > /dev/null 2>&1
  ```
## 3.4 spark入es监控(jenkins)
- 服务器：183.136.128.47
  ```
  #自建spark入es
  ssh -p23432 172.18.54.147 "/bbd/ssd01/zz/shell/jxLogToEs/spark-jxLogToEs-watch.sh"
  #融合spark入es
  ssh -p23432 172.18.54.142 "nohup /bbd/ssd01/zrk/task/spark-es-watch.sh > /dev/null 2>&1 &"
  #自建CDN spark带宽计算
  ssh -p23432 172.18.54.145 " nohup /bbd/sata09/bigdata/sinobbd/task/weixin/runjxbandstatis.sh > /dev/null 2>&1 &"
  #融合CDN spark 带宽计算
  ssh -p23432 172.18.54.145 " nohup /bbd/sata09/bigdata/sinobbd/task/weixin/fusionstatis.sh > /dev/null 2>&1 &"
  ```
## 3.5 快手post数据监控(jenkins)
- 服务器：54.162
  ```
  9,19,29,39,49,59 * * * *
  /bbd/sata01/shell/task/ks_http_kafka-watch.sh
  ```

## 3.6 快手质量数据日志（fiile）删除(jenkins)
- 服务器：128.49
  ```
  00 10 * * *
  /bbd/ssd01/zz/shell/task/03_kuaishou_filelog/delete_ksfilelog.sh
  ```
## 3.7 打包日志定时删除(jenkins)
- 服务器：183.136.128.47
  ```
  00 12 * * *
  ssh -p23432 172.18.54.147 "nohup /bbd/ssd01/zz/shell/crontab_delete_logpackagelog/crontab_delete_logpackagelog.sh > /dev/null 2>&1 &"
  ```
## 3.8 融合日志备份、删除(jenkins)
- 服务器：183.136.128.47
  ```
  00 05 * * *
  /bbd/ssd01/zz/shell/my_ssh.sh flume "nohup /bbd/ssd01/zz/shell/task/01_bakc_del/delete_firm_logs.sh > /dev/null 2>&1 &" #删除7天前的融合的解压后的日志
  ```
## 3.9 日志监控_fluentd处理快手日志(jenkins)
- 服务器：183.136.128.47
  ```
  * * * * *
  /bbd/ssd01/zz/shell/task/01_watch/ks_logs_watch/ks_td_log_watch_main.sh
  ```
## 3.10 日志监控_flume(jenkins)
- 服务器：183.136.128.47
  ```
  * * * * *
  /bbd/ssd01/zz/shell/task/01_watch/flume_log_watch/flume_logs_watch_main.sh
  ```

## 3.11 每天早上发送前三天jx、rh日志大小，带宽峰值(jenkins)
- 服务器：183.136.128.47
  ```
  00 08 * * *
  /bbd/ssd01/zz/shell/task/01_watch/send_weixin_filesize_stats/send_weixin_message.sh
  ```
## 3.12 自建kafka，lag监控(jenkins)
- 服务器：183.131.54.162
  ```
  */10 * * * *
  /bbd/sata01/shell/task/jx-kafka-watch.sh
  ```
## 3.13 融合kafka,lag监控(jenkins)
- 服务器：183.131.54.162
  ```
  * * * * *
  /bbd/sata01/shell/task/rh-kafka-watch.sh
  ```
## 3.14 融合日志文件分布情况统计入es(jenkins)
- 服务器：183.136.128.47
  ```
  00 07 * * *
  /bbd/ssd01/zz/shell/task/01_watch/rh_log_distri/rh_log_distri_main.sh
  ```
## 3.15 融合日志文件未处理个数监控报警(jenkins)
- 服务器：183.136.128.47
  ```
  */5 * * * *
  /bbd/ssd01/zz/shell/task/01_watch/rh_file_watch_main.sh "rh_file" "1000"
  ```
## 3.16 融合本地磁盘未消费文件、条数统计(jenkins)
- 服务器：183.136.128.47
  ```
  * * * * *
  /bbd/ssd01/zz/shell/my_ssh.sh flume "nohup
  /bbd/ssd01/zz/shell/task/01_watch/diskfile_count_message.sh &"
  ```


# 打包前12h
- PostDomain.py从boss获取按天打包的域名
    - 写入domain.conf，异常调用发送信息到微信方法
    - 打包之前调用，获取域名打包粒度参考：XXXXXXXXXXXXXXXXXXXX

- 打包12h的日志（output_path=/export/logs/downloadlogs_jx_rh）
  - 打包条件：入库时间范围前天00:00 到 今天4:00，日志时间为指定小时的
  - 打包时间：00 01 * * *
  - 00..11点循环打包，输出路径：$output_path/$logday_1
  - 每打包1h的，调用一次文件移动：$output_path/$logday_1/$i下的按天打包的域名 移动到 $output_path/$logday 路径下
  - 是否移动完成简单判断：判断正在移动文件的进程的个数，判断正常移动的记录数
- 合并
    - 合并12h的日志，按天打包的最后12h打包完成后合并,合并到目录：$output_path/$logday_merge
- 下载
  - 前12h的日志按小时循环下载，目的地：/bbd/nfs/customer_logs/$logday

# 打包后12h
- PostDomain.py从boss获取按天打包的域名
    - 写入domain.conf，异常调用发送信息到微信方法
    - 打包之前调用，获取域名打包粒度参考：XXXXXXXXXXXXXXXXXXXX

- 打包后12h的日志（output_path=/export/logs/downloadlogs_jx_rh）
  - 打包条件：入库时间范围前天00:00 到 今天4:00，日志时间为指定小时的
  - 打包打包时间：00 04 * * *
  - 12..23点循环打包，输出路径：$output_path/$logday
  - 每1h的，调用一次文件移动：$output_path/$logday/$i下的按天打包的域名 移动到 $output_path/$logday 路径下
  - 是否移动完成简单判断：判断正在移动文件的进程的个数，判断正常移动的记录数
- 合并
    - 合并后12h的日志 和 按天打包的日志，合并到目录：$output_path/$logday_merge
- 下载
  - 下载按天打包的，后12h的日志按小时循环下载，目的地：/bbd/nfs/customer_logs/$logday
- 文件重新命名
  - 正常包小时的：/bbd/nfs/customer_logs/20180224/hour/zunyi.chexun.com/zunyi.chexun.com_201802240000_IBokpV.log.gz
  - 正常包天的：/bbd/nfs/customer_logs/20180224/day/c2.v.svedio.cn/c2.v.svedio.cn_201802240000_cD9MSx.log.gz

  - 小时、天的日志包 目录结构 已和客户约定好，变化要通知客户
- 入库url
  - 正常日志、延迟日志入库 bose接口，参考XXXXXXXXX

# 延迟包
- output_path=/export/logs/downloadlogs_rh_timeout
- 打包延迟日志包
  - 前天和大前天的表，入库时间：昨天4:00 到 今天4:00
  - 输出目录：$output_path/$logday
- 合并
  - 合并输出目录：$output_path/$logday_merge
- 下载
  - 下载目录：/bbd/nfs/customer_logs/logs_timeout
- 文件重新命名
   - 延迟包：/bbd/nfs/customer_logs/20180224/day/ypyun.sinobbd.com/ypyun.sinobbd.com_201802240000_8kA1PH.timeout.log.gz
- 入库url